{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Deep Neural Network for Breast Cancer Classification](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to build and train a deep neural network for classification using the PyTorch library. The dataset used is the Breast Cancer Wisconsin (Diagnostic) Data Set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Deep Neural Network for Breast Cancer Classification](#toc1_)    \n",
    "  - [Objectives](#toc1_1_)    \n",
    "  - [Background](#toc1_2_)    \n",
    "    - [What is PyTorch](#toc1_2_1_)    \n",
    "  - [Setup](#toc1_3_)    \n",
    "    - [Installing Required Libraries](#toc1_3_1_)    \n",
    "  - [Load the Data](#toc1_4_)    \n",
    "    - [Breast Cancer Wisconsin (Diagnostic)](#toc1_4_1_)    \n",
    "  - [Data Preprocessing](#toc1_5_)    \n",
    "  - [Build and Train the Neural Network Model](#toc1_6_)    \n",
    "  - [Visualize the Training and Test Loss](#toc1_7_)    \n",
    "  - [Exercises](#toc1_8_)    \n",
    "    - [Exercise 1 - Change to different optimizer: SGD](#toc1_8_1_)    \n",
    "    - [Exercise 2 - Change the number of neurons](#toc1_8_2_)    \n",
    "    - [Exercise 3 - Try different dataset - Iris Dataset](#toc1_8_3_)    \n",
    "  - [Authors](#toc1_9_)    \n",
    "  - [Contributors](#toc1_10_)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Objectives](#toc0_)\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    " - Use PyTorch to build and train a deep neural network for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Background](#toc0_)\n",
    "\n",
    "### <a id='toc1_2_1_'></a>[What is PyTorch](#toc0_)\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is an open-source machine learning library, developed by Facebook's AI Research lab (FAIR). It is primarily used for applications in areas such as computer vision and natural language processing.\n",
    "\n",
    "**Common Uses of PyTorch**\n",
    "\n",
    "- **Developing Deep Learning Models**: From standard feed-forward networks to complex neural networks like CNNs and RNNs.\n",
    "- **Research and Experimentation**: Facilitates rapid prototyping, which is highly valued in academic and research settings.\n",
    "- **Production Deployment**: With the support of TorchServe, PyTorch models can be easily transitioned from research to production environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Setup](#toc0_)\n",
    "\n",
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/) for mathematical operations.\n",
    "*   [`matplotlib`](https://matplotlib.org/) for additional plotting tools.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`torch`](https://pytorch.org/) for building and training the deep neural network.\n",
    "*   [`ucimlrepo`](https://pypi.org/project/ucimlrepo/) for loading the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Installing Required Libraries](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.2.2\n",
      "  Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas==2.2.2)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas==2.2.2) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.2)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m138.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.2 pandas-2.2.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.2\n",
      "    Uninstalling numpy-2.3.2:\n",
      "      Successfully uninstalled numpy-2.3.2\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib==3.8.0\n",
      "  Downloading matplotlib-3.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.8.0)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.8.0)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.8.0)\n",
      "  Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (109 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib==3.8.0)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.0) (24.2)\n",
      "Collecting pillow>=6.2.0 (from matplotlib==3.8.0)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.8.0)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.8.0) (1.17.0)\n",
      "Downloading matplotlib-3.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.8.0 pillow-11.3.0 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn==1.5.0\n",
      "  Downloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn==1.5.0) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn==1.5.0)\n",
      "  Downloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn==1.5.0)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.0)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m136.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.5.0 scipy-1.16.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch==2.3.1\n",
      "  Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch==2.3.1)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (4.12.2)\n",
      "Collecting sympy (from torch==2.3.1)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.3.1)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.3.1) (3.1.5)\n",
      "Collecting fsspec (from torch==2.3.1)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.3.1)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.1-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed filelock-3.19.1 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 sympy-1.14.0 torch-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ucimlrepo==0.0.7\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from ucimlrepo==0.0.7) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in /opt/conda/lib/python3.12/site-packages (from ucimlrepo==0.0.7) (2024.12.14)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.0.0->ucimlrepo==0.0.7) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo==0.0.7) (1.17.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas==2.2.2\n",
    "%pip install numpy==1.26.4\n",
    "%pip install matplotlib==3.8.0\n",
    "%pip install scikit-learn==1.5.0\n",
    "%pip install torch==2.3.1\n",
    "%pip install ucimlrepo==0.0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Load the Data](#toc0_)\n",
    "\n",
    "### <a id='toc1_4_1_'></a>[Breast Cancer Wisconsin (Diagnostic)](#toc0_)\n",
    "\n",
    "The [Breast Cancer Wisconsin (Diagnostic) dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) is a classic dataset used for classification tasks. It contains 569 samples of breast cancer cells, each with 30 features. The dataset is divided into two classes: benign and malignant. The goal is to classify the breast cancer cells into one of the two classes.\n",
    "\n",
    "This dataset is free to use and is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n",
    "\n",
    "First, we need to load our dataset and take a look at its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius3</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
       "0    17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
       "1    20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
       "2    19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
       "3    11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
       "4    20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
       "\n",
       "   concavity1  concave_points1  symmetry1  fractal_dimension1  ...  radius3  \\\n",
       "0      0.3001          0.14710     0.2419             0.07871  ...    25.38   \n",
       "1      0.0869          0.07017     0.1812             0.05667  ...    24.99   \n",
       "2      0.1974          0.12790     0.2069             0.05999  ...    23.57   \n",
       "3      0.2414          0.10520     0.2597             0.09744  ...    14.91   \n",
       "4      0.1980          0.10430     0.1809             0.05883  ...    22.54   \n",
       "\n",
       "   texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
       "0     17.33      184.60  2019.0       0.1622        0.6656      0.7119   \n",
       "1     23.41      158.80  1956.0       0.1238        0.1866      0.2416   \n",
       "2     25.53      152.50  1709.0       0.1444        0.4245      0.4504   \n",
       "3     26.50       98.87   567.7       0.2098        0.8663      0.6869   \n",
       "4     16.67      152.20  1575.0       0.1374        0.2050      0.4000   \n",
       "\n",
       "   concave_points3  symmetry3  fractal_dimension3  \n",
       "0           0.2654     0.4601             0.11890  \n",
       "1           0.1860     0.2750             0.08902  \n",
       "2           0.2430     0.3613             0.08758  \n",
       "3           0.2575     0.6638             0.17300  \n",
       "4           0.1625     0.2364             0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Diagnosis\n",
       "0         M\n",
       "1         M\n",
       "2         M\n",
       "3         M\n",
       "4         M"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "\n",
    "# print the first few rows of the data\n",
    "display(X.head())\n",
    "\n",
    "# print the first few rows of the target\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let us check the shape of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X shape: (569, 30)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y shape: (569, 1)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f'X shape: {X.shape}')\n",
    "display(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset has 569 samples and 30 features. The target variable is the diagnosis column, which contains the class labels for each sample. The class labels are either 'M' (malignant) or 'B' (benign).\n",
    "\n",
    "We will then check the distribution of the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "B    357\n",
       "M    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y['Diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dataset is **imbalanced**, with more benign samples than malignant samples. \n",
    "\n",
    "We will now process the data. Randomly choose 200 samples in 'M' (malignant) and 200 samples in 'B' (benign).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "B    200\n",
       "M    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine features and target into a single DataFrame for easier manipulation\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Separate the two classes\n",
    "data_B = data[data['Diagnosis'] == 'B']\n",
    "data_M = data[data['Diagnosis'] == 'M']\n",
    "\n",
    "# Select 200 samples from each class\n",
    "data_B = data_B.sample(n=200, random_state=42)\n",
    "data_M = data_M.sample(n=200, random_state=42)\n",
    "\n",
    "# Combine the two classes\n",
    "balanced_data = pd.concat([data_B, data_M])\n",
    "\n",
    "display(balanced_data['Diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 200 samples in each class, with a total of 400 samples. It means that the dataset is balanced.\n",
    "\n",
    "We will use 80% of the samples for training and 20% for testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Data Preprocessing](#toc0_)\n",
    "\n",
    "Before feeding the data into our neural network, we need to preprocess it. This involves separating the features and labels, splitting the data into training and test sets, and standardizing the feature values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius1</th>\n",
       "      <th>texture1</th>\n",
       "      <th>perimeter1</th>\n",
       "      <th>area1</th>\n",
       "      <th>smoothness1</th>\n",
       "      <th>compactness1</th>\n",
       "      <th>concavity1</th>\n",
       "      <th>concave_points1</th>\n",
       "      <th>symmetry1</th>\n",
       "      <th>fractal_dimension1</th>\n",
       "      <th>...</th>\n",
       "      <th>radius3</th>\n",
       "      <th>texture3</th>\n",
       "      <th>perimeter3</th>\n",
       "      <th>area3</th>\n",
       "      <th>smoothness3</th>\n",
       "      <th>compactness3</th>\n",
       "      <th>concavity3</th>\n",
       "      <th>concave_points3</th>\n",
       "      <th>symmetry3</th>\n",
       "      <th>fractal_dimension3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>14.060</td>\n",
       "      <td>17.18</td>\n",
       "      <td>89.75</td>\n",
       "      <td>609.1</td>\n",
       "      <td>0.08045</td>\n",
       "      <td>0.05361</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.03251</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.05764</td>\n",
       "      <td>...</td>\n",
       "      <td>14.92</td>\n",
       "      <td>25.34</td>\n",
       "      <td>96.42</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.08460</td>\n",
       "      <td>0.07911</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>0.06609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>9.777</td>\n",
       "      <td>16.99</td>\n",
       "      <td>62.50</td>\n",
       "      <td>290.2</td>\n",
       "      <td>0.10370</td>\n",
       "      <td>0.08404</td>\n",
       "      <td>0.043340</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.07065</td>\n",
       "      <td>...</td>\n",
       "      <td>11.05</td>\n",
       "      <td>21.47</td>\n",
       "      <td>71.68</td>\n",
       "      <td>367.0</td>\n",
       "      <td>0.14670</td>\n",
       "      <td>0.17650</td>\n",
       "      <td>0.13000</td>\n",
       "      <td>0.05334</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.08468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>13.900</td>\n",
       "      <td>19.24</td>\n",
       "      <td>88.73</td>\n",
       "      <td>602.9</td>\n",
       "      <td>0.07991</td>\n",
       "      <td>0.05326</td>\n",
       "      <td>0.029950</td>\n",
       "      <td>0.02070</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.05594</td>\n",
       "      <td>...</td>\n",
       "      <td>16.41</td>\n",
       "      <td>26.42</td>\n",
       "      <td>104.40</td>\n",
       "      <td>830.5</td>\n",
       "      <td>0.10640</td>\n",
       "      <td>0.14150</td>\n",
       "      <td>0.16730</td>\n",
       "      <td>0.08150</td>\n",
       "      <td>0.2356</td>\n",
       "      <td>0.07603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>12.460</td>\n",
       "      <td>12.83</td>\n",
       "      <td>78.83</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.07372</td>\n",
       "      <td>0.04043</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.01149</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.06013</td>\n",
       "      <td>...</td>\n",
       "      <td>13.19</td>\n",
       "      <td>16.36</td>\n",
       "      <td>83.24</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0.09439</td>\n",
       "      <td>0.06477</td>\n",
       "      <td>0.01674</td>\n",
       "      <td>0.02680</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.07028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>11.710</td>\n",
       "      <td>16.67</td>\n",
       "      <td>74.72</td>\n",
       "      <td>423.6</td>\n",
       "      <td>0.10510</td>\n",
       "      <td>0.06095</td>\n",
       "      <td>0.035920</td>\n",
       "      <td>0.02600</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.05945</td>\n",
       "      <td>...</td>\n",
       "      <td>13.33</td>\n",
       "      <td>25.48</td>\n",
       "      <td>86.16</td>\n",
       "      <td>546.7</td>\n",
       "      <td>0.12710</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.10460</td>\n",
       "      <td>0.06968</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.07343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>15.320</td>\n",
       "      <td>17.27</td>\n",
       "      <td>103.20</td>\n",
       "      <td>713.3</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.22840</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.07596</td>\n",
       "      <td>...</td>\n",
       "      <td>17.73</td>\n",
       "      <td>22.66</td>\n",
       "      <td>119.80</td>\n",
       "      <td>928.8</td>\n",
       "      <td>0.17650</td>\n",
       "      <td>0.45030</td>\n",
       "      <td>0.44290</td>\n",
       "      <td>0.22290</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.11910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>16.270</td>\n",
       "      <td>20.71</td>\n",
       "      <td>106.90</td>\n",
       "      <td>813.7</td>\n",
       "      <td>0.11690</td>\n",
       "      <td>0.13190</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.08488</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>0.06277</td>\n",
       "      <td>...</td>\n",
       "      <td>19.28</td>\n",
       "      <td>30.38</td>\n",
       "      <td>129.80</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>0.15900</td>\n",
       "      <td>0.29470</td>\n",
       "      <td>0.35970</td>\n",
       "      <td>0.15830</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.08200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>14.450</td>\n",
       "      <td>20.22</td>\n",
       "      <td>94.49</td>\n",
       "      <td>642.7</td>\n",
       "      <td>0.09872</td>\n",
       "      <td>0.12060</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.05980</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.06466</td>\n",
       "      <td>...</td>\n",
       "      <td>18.33</td>\n",
       "      <td>30.12</td>\n",
       "      <td>117.90</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>0.15520</td>\n",
       "      <td>0.40560</td>\n",
       "      <td>0.49670</td>\n",
       "      <td>0.18380</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>0.10130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14.860</td>\n",
       "      <td>23.21</td>\n",
       "      <td>100.40</td>\n",
       "      <td>671.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.08878</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06672</td>\n",
       "      <td>...</td>\n",
       "      <td>16.08</td>\n",
       "      <td>27.78</td>\n",
       "      <td>118.60</td>\n",
       "      <td>784.7</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.46480</td>\n",
       "      <td>0.45890</td>\n",
       "      <td>0.17270</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.08701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>15.750</td>\n",
       "      <td>20.25</td>\n",
       "      <td>102.60</td>\n",
       "      <td>761.3</td>\n",
       "      <td>0.10250</td>\n",
       "      <td>0.12040</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.06462</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.06303</td>\n",
       "      <td>...</td>\n",
       "      <td>19.56</td>\n",
       "      <td>30.29</td>\n",
       "      <td>125.90</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>0.15520</td>\n",
       "      <td>0.44800</td>\n",
       "      <td>0.39760</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.10640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius1  texture1  perimeter1  area1  smoothness1  compactness1  \\\n",
       "395   14.060     17.18       89.75  609.1      0.08045       0.05361   \n",
       "110    9.777     16.99       62.50  290.2      0.10370       0.08404   \n",
       "481   13.900     19.24       88.73  602.9      0.07991       0.05326   \n",
       "493   12.460     12.83       78.83  477.3      0.07372       0.04043   \n",
       "136   11.710     16.67       74.72  423.6      0.10510       0.06095   \n",
       "..       ...       ...         ...    ...          ...           ...   \n",
       "257   15.320     17.27      103.20  713.3      0.13350       0.22840   \n",
       "328   16.270     20.71      106.90  813.7      0.11690       0.13190   \n",
       "199   14.450     20.22       94.49  642.7      0.09872       0.12060   \n",
       "194   14.860     23.21      100.40  671.4      0.10440       0.19800   \n",
       "223   15.750     20.25      102.60  761.3      0.10250       0.12040   \n",
       "\n",
       "     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  radius3  \\\n",
       "395    0.026810          0.03251     0.1641             0.05764  ...    14.92   \n",
       "110    0.043340          0.01778     0.1584             0.07065  ...    11.05   \n",
       "481    0.029950          0.02070     0.1579             0.05594  ...    16.41   \n",
       "493    0.007173          0.01149     0.1613             0.06013  ...    13.19   \n",
       "136    0.035920          0.02600     0.1339             0.05945  ...    13.33   \n",
       "..          ...              ...        ...                 ...  ...      ...   \n",
       "257    0.244800          0.12420     0.2398             0.07596  ...    17.73   \n",
       "328    0.147800          0.08488     0.1948             0.06277  ...    19.28   \n",
       "199    0.118000          0.05980     0.1950             0.06466  ...    18.33   \n",
       "194    0.169700          0.08878     0.1737             0.06672  ...    16.08   \n",
       "223    0.114700          0.06462     0.1935             0.06303  ...    19.56   \n",
       "\n",
       "     texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
       "395     25.34       96.42   684.5      0.10660       0.12310     0.08460   \n",
       "110     21.47       71.68   367.0      0.14670       0.17650     0.13000   \n",
       "481     26.42      104.40   830.5      0.10640       0.14150     0.16730   \n",
       "493     16.36       83.24   534.0      0.09439       0.06477     0.01674   \n",
       "136     25.48       86.16   546.7      0.12710       0.10280     0.10460   \n",
       "..        ...         ...     ...          ...           ...         ...   \n",
       "257     22.66      119.80   928.8      0.17650       0.45030     0.44290   \n",
       "328     30.38      129.80  1121.0      0.15900       0.29470     0.35970   \n",
       "199     30.12      117.90  1044.0      0.15520       0.40560     0.49670   \n",
       "194     27.78      118.60   784.7      0.13160       0.46480     0.45890   \n",
       "223     30.29      125.90  1088.0      0.15520       0.44800     0.39760   \n",
       "\n",
       "     concave_points3  symmetry3  fractal_dimension3  \n",
       "395          0.07911     0.2523             0.06609  \n",
       "110          0.05334     0.2533             0.08468  \n",
       "481          0.08150     0.2356             0.07603  \n",
       "493          0.02680     0.2280             0.07028  \n",
       "136          0.06968     0.1712             0.07343  \n",
       "..               ...        ...                 ...  \n",
       "257          0.22290     0.3258             0.11910  \n",
       "328          0.15830     0.3103             0.08200  \n",
       "199          0.18380     0.4753             0.10130  \n",
       "194          0.17270     0.3000             0.08701  \n",
       "223          0.14790     0.3993             0.10640  \n",
       "\n",
       "[400 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "395    0\n",
       "110    0\n",
       "481    0\n",
       "493    0\n",
       "136    0\n",
       "      ..\n",
       "257    1\n",
       "328    1\n",
       "199    1\n",
       "194    1\n",
       "223    1\n",
       "Name: Diagnosis, Length: 400, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "# Separate features and targets\n",
    "X = balanced_data.drop('Diagnosis', axis=1)\n",
    "y = balanced_data['Diagnosis']\n",
    "\n",
    "# Convert the targets to binary labels\n",
    "y = y.map({'B': 0, 'M': 1})\n",
    "\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be split into **80%** training and **20%** test sets.\n",
    "\n",
    "We then print the shapes of the training and test sets to verify that the data has been split correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_train shape: (320, 30)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_train shape: (320,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'X_test shape: (80, 30)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_test shape: (80,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "display(f'X_train shape: {X_train.shape}')\n",
    "display(f'y_train shape: {y_train.shape}')\n",
    "display(f'X_test shape: {X_test.shape}')\n",
    "display(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we standardize the feature values using the `StandardScaler` from scikit-learn.\n",
    "\n",
    "Standardizing the data involves transforming the features so that they have a mean of 0 and a standard deviation of 1. This helps in ensuring that all features contribute equally to the result and helps the model converge faster during training.\n",
    "\n",
    "1. **Fitting the Scaler**: We calculate the mean and standard deviation for each feature in the training set using the `fit` method of the `StandardScaler`.\n",
    "2. **Transforming the Training Data**: We apply the standardization to the training data using the `transform` method, which scales the features accordingly.\n",
    "3. **Transforming the Test Data**: We apply the same transformation to the test data using the same scaler. This ensures that both training and test sets are standardized in the same way.\n",
    "\n",
    "By standardizing the data, we make sure that each feature contributes equally to the training process, which helps in achieving better performance and faster convergence of the neural network model.\n",
    "\n",
    "Finally, we convert the NumPy arrays to PyTorch tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Standardize the data\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# Transform the test data using the same scaler\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and test sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Build and Train the Neural Network Model](#toc0_)\n",
    "\n",
    "We will define our neural network architecture, specify the loss function and optimizer, and then train the model.\n",
    "\n",
    "First, we define the neural network architecture using the `nn.Module` class in PyTorch. Our model consists of an input layer, one hidden layer, and an output layer with 2 neurons corresponding to the 2 classes.\n",
    "\n",
    "Below is an example of the neural network model, it has 8 neurons in the input layer, 8 neurons in the hidden layer, and 2 neurons in the output layer.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/j-MFHvfzhrY04qVMsClOGA/8-8-2.jpg\" alt=\"image\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, input_units=30, hidden_units=64, output_units=2):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_units, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, output_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = ClassificationNet(input_units=30, hidden_units=64, output_units=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the neural network architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassificationNet(\n",
      "  (fc1): Linear(in_features=30, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the loss function and optimizer. We use the `CrossEntropyLoss` loss function, which is commonly used for multi-class classification problems. The `Adam` optimizer is used to update the weights of the neural network during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can train the model using the training data. We iterate over the training data for a specified number of epochs and update the weights of the neural network using backpropagation.\n",
    "\n",
    "During training, we calculate the loss at each epoch and print it to monitor the training progress. The loss should **decrease** over time as the model learns to classify the classes correctly.\n",
    "\n",
    "Finally, we evaluate the model on the test data to see how well it performs on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.2833, Test Loss: 0.1863\n",
      "Epoch [2/10], Train Loss: 0.1245, Test Loss: 0.1387\n",
      "Epoch [3/10], Train Loss: 0.0948, Test Loss: 0.1228\n",
      "Epoch [4/10], Train Loss: 0.0834, Test Loss: 0.1168\n",
      "Epoch [5/10], Train Loss: 0.0742, Test Loss: 0.1138\n",
      "Epoch [6/10], Train Loss: 0.0691, Test Loss: 0.1084\n",
      "Epoch [7/10], Train Loss: 0.0648, Test Loss: 0.1031\n",
      "Epoch [8/10], Train Loss: 0.0594, Test Loss: 0.1015\n",
      "Epoch [9/10], Train Loss: 0.0548, Test Loss: 0.0970\n",
      "Epoch [10/10], Train Loss: 0.0512, Test Loss: 0.0974\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation phase on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            test_outputs = model(X_batch)\n",
    "            loss = criterion(test_outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Visualize the Training and Test Loss](#toc0_)\n",
    "\n",
    "Plotting the loss curves helps us understand the training dynamics of our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), test_losses, label='Test Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[Exercises](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_8_1_'></a>[Exercise 1 - Change to different optimizer: SGD](#toc0_)\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is a widely used optimization algorithm in machine learning and deep learning for training models. It is an iterative method for optimizing a loss function by making small updates to the model parameters in the direction of the negative gradient.\n",
    "\n",
    "**How SGD Works**\n",
    "\n",
    "SGD updates the model's parameters iteratively. The update rule for each parameter $\\theta$ is as follows:\n",
    "\n",
    "$$ \\theta = \\theta - \\eta \\cdot \\nabla_\\theta J(\\theta) $$\n",
    "\n",
    "where:\n",
    "- $\\theta$ represents the model parameters.\n",
    "- $\\eta$ (eta) is the learning rate, which controls the step size of each update.\n",
    "- $\\nabla_\\theta J(\\theta)$ is the gradient of the loss function with respect to the parameter $\\theta$.\n",
    "\n",
    "**PyTorch's `torch.optim.SGD`**\n",
    "\n",
    "In PyTorch, the `torch.optim.SGD` optimizer provides several parameters to configure its behavior.\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "1. **`params`**: \n",
    "   - The model parameters to optimize.\n",
    "   - Typically provided as `model.parameters()`.\n",
    "\n",
    "2. **`lr` (learning rate)**: \n",
    "   - A positive float value that controls the step size for each parameter update.\n",
    "   - Example: `lr=0.01`.\n",
    "\n",
    "3. **`momentum`** (optional): \n",
    "   - A float value that accelerates SGD in the relevant direction and dampens oscillations.\n",
    "   - Example: `momentum=0.9`.\n",
    "\n",
    "4. **`weight_decay`** (optional): \n",
    "   - A float value representing the L2 penalty (regularization term) to prevent overfitting.\n",
    "   - Example: `weight_decay=0.0001`.\n",
    "\n",
    "5. **`dampening`** (optional): \n",
    "   - A float value that reduces the effect of the momentum.\n",
    "   - Default is `0`.\n",
    "\n",
    "**Example Usage**\n",
    "\n",
    "Here’s how you can use `torch.optim.SGD` with some of these parameters:\n",
    "\n",
    "```python\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model_new_optimizer = ClassificationNet(input_units=30, hidden_units=64, output_units=2)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model_new_optimizer.parameters(), lr=0.001) # Here, change the optimizer to SGD\n",
    "\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model_new_optimizer.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_new_optimizer(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation phase on test set\n",
    "    model_new_optimizer.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            test_outputs = model_new_optimizer(X_batch)\n",
    "            loss = criterion(test_outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), test_losses, label='Test Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "optimizer = optim.SGD(model_new_optimizer.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001) # Here, change the optimizer to SGD\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_8_2_'></a>[Exercise 2 - Change the number of neurons](#toc0_)\n",
    "\n",
    "Define a new neural network architecture with different neurons and see how it affects the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of hidden units, e.g. 16.\n",
    "model_new = ClassificationNet(input_units=30, hidden_units=32, output_units=2)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_new.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model_new.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_new(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation phase on test set\n",
    "    model_new.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            test_outputs = model_new(X_batch)\n",
    "            loss = criterion(test_outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), test_losses, label='Test Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "model_new = ClassificationNet(input_units=30, hidden_units=16, output_units=2)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_8_3_'></a>[Exercise 3 - Try different dataset - Iris Dataset](#toc0_)\n",
    "\n",
    "Try using the [Iris dataset](https://archive.ics.uci.edu/dataset/53/iris) for classification. The Iris dataset is a classic dataset used for classification tasks. It contains 150 samples of iris flowers, each with 4 features. The dataset is divided into three classes, with each class representing a different species of iris flower. The goal is to classify the iris flowers into one of the three classes.\n",
    "\n",
    "This dataset is free to use and is licensed under a Creative Commons Attribution 4.0 International (CC BY 4.0) license.\n",
    "\n",
    "You can load the Iris dataset using the following code:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features and target variable\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "```\n",
    "\n",
    "You can then preprocess the data, build and train the neural network model, and evaluate its performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract the features and target variable\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42, stratify=y_iris)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader for training and test sets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class IrisNet(nn.Module):\n",
    "    def __init__(self, hidden_units=8):\n",
    "        super(IrisNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, hidden_units)  # 4 input features for Iris dataset\n",
    "        self.fc2 = nn.Linear(hidden_units, 3)  # 3 output classes for Iris dataset\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = IrisNet(hidden_units=8)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Evaluation phase on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            test_outputs = model(X_batch)\n",
    "            loss = criterion(test_outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), test_losses, label='Test Loss', linestyle='--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_9_'></a>[Authors](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Ricky Shi](https://www.linkedin.com/in/ricky-shi-ca/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_10_'></a>[Contributors](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wojciech \"Victor\" Fulmyk](https://www.linkedin.com/in/wfulmyk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "© Copyright IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "67792b7f280bc83a121263f37dc2a55f0e24b9c523254c8503674708ac6a3d64"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
